<!--
This is for including Chapter 1.  Notice that it's also good practice to name your chunk.  This will help you debug potential issues as you knit.  The chunk above is called intro and the one below is called chapter1.  Feel free to change the name of the Rmd file as you wish, but don't forget to change it here from chap1.Rmd.
-->

<!--
The {#rmd-basics} text after the chapter declaration will allow us to link throughout the document back to the beginning of Chapter 1.  These labels will automatically be generated (if not specified) by changing the spaces to hyphens and capital letters to lowercase.  Look for the reference to this label at the beginning of Chapter 2.
-->

# Metodología y datos

## Caso de estudio

El caso de estudio utilizado en este trabajo corresponde a un SCM que se inicio y alcanzo su madurez durante el 22 de noviembre de 2018 en el centro y norte de Argentina. Previo al desarrollo de este SCM, el centro y norte de Argentina se encontraba inmerso en una masa de aire cálido y húmedo con altos valores de energía potencial disponible convectiva (CAPE), como lo muestra ERA 5 [@era5pressure] en la Figura \@ref(fig:caso)a. El 22 de noviembre de 2018 un frente frío cruzó el centro de Argentina (Figura \@ref(fig:caso)b). Este frente frío desencadenó el desarrollo de células convectivas aisladas que rápidamente crecieron hasta convertirse en un SCM excepcionalmente grande que puede observarse en las imágenes de temperatura de brillo del canal 13 de GOES-16 (Figura \@ref(fig:caso)d,e). Durante ese día, varias estaciones de superficie observaron actividad eléctrica, fuertes ráfagas de viento y lluvias intensas. Al norte de la región, el entorno cálido y húmedo contribuyó al desarrollo de convección aislada que finalmente creció y se fusionó con el SCM (Figura \@ref(fig:caso)f). El SCM recorrió aproximadamente 2500 km de sur a norte, disipándose sobre Paraguay y el sur de Brasil después de 42 horas desde el inicio de su desarrollo. Este caso estudio es de particular interes por desarrollarse durante la campaña RELAMPAGO donde se generaron observaciones extraordinarias que serán utilizadas en la verificación de los experimentos desarrollados. 

(ref:caso) Presión a nivel del mar (hPa, contornos negros), espesor 1000-500 hPa (contornos rojos discontinuos) y energía potencial convectiva disponible (sombreada) según ERA5 y temperatura de brillo del canal 13 de GOES-16 para a,d) 00 y b,e) 12 UTC, 22 de Nov y c,f) 00 UTC, 23 de Nov. 

```{r caso, fig.cap="(ref:caso)", fig.align="center", fig.width=6, fig.height=4}
#
campos <- ReadNetCDF(here("data/derived_data/reanalysis/geopotential.nc")) %>% 
  dcast(time + longitude + latitude ~ level) %>% 
  .[order(time, -latitude, longitude)] %>% 
  .[, ":="(msl = ReadNetCDF(here("data/derived_data/reanalysis/pressure-pw.nc"), vars = "msl", out = "vector")[[1]],
           cape = ReadNetCDF(here("data/derived_data/reanalysis/cape-pw.nc"), vars = "cape", out = "vector")[[1]])] %>% 
  setnames(c("longitude", "latitude"), c("lon", "lat")) %>% 
    .[time != ymd_h(2018112312)] 

xlim <- c(2700, 3950)
ylim <- c(3800, 4950)

files <- Sys.glob(here("data/derived_data/goes16/*"))
goes <- map(files, function(f) {
  nc <- ncdf4::nc_open(f)
  meta <- unglue::unglue(basename(f), "OR_ABI-L1b-RadF-M3{channel}_G16_s{sdate}_e{edate}_c{cdate}.nc")
  ReadNetCDF(f, vars = c(rad = "Rad", time = "t"), 
             subset = list(x = xlim, y = ylim)) %>% 
  .[, rad := calculate_rad(rad, nc)] %>% 
  .[, tb := rad_to_tb(rad, nc)] %>% 
  .[, time := as_datetime(time, origin = "2000-01-01 12:00:00")] %>%
  .[, c("lon", "lat") := goes_projection(x, y, nc)] %>% 
  .[]
}) %>% 
  rbindlist() %>% 
  .[, time := floor_date(time, "hour")]

campos %>% 
  .[, source := "era5"] %>%
  .[, time := factor(time)] %>% 
  .[, ":="(espesor = (`500`-`1000`)/100, time = factor(time))] %>%
  ggplot(aes(lon, lat)) +
  geom_contour_fill(aes(z = cape, fill = stat(level_d)), breaks = seq(500, 4000, 500)) +
  scale_fill_distiller(super = ScaleDiscretised,
                       name = "CAPE",
                       # palette = "PRGn", direction = 1,
                       palette = "YlOrRd", direction = 1,
                       guide = guide_colorsteps(barwidth = 0.5, #mid = 25,
                                                barheight = 8,
                                                order = 2, 
                                                # title.position = "left",
                                                # title.vjust = 1,
                                                frame.colour = "black")) +
  geom_contour2(aes(z = espesor, label = ..level..),
                size = 0.2, color = "darkred", linetype = 2,
                label_size = 2, label.placer = label_placer_n(n = 3)) +
  geom_contour2(aes(z = msl/100, label = ..level..),
                size = 0.4, color = "black", linetype = 1,
                label_size = 2) +
  cordillera +
  scattermore::geom_scattermore(data = goes[, source := "goes"], aes(color = tb)) +
  scale_color_topes(guide = guide_colorbar(barwidth = 0.5,
                                           barheight = 8,
                                           order = 99,
                                           frame.colour = "black")) +
  # guides(fill = guide_legend(" CAPE", order = 0),
  #        color = guide_legend("BT (ºC)", order = 2)) +
  geom_mapa() +
  coord_sf(ylim = c(-45, -22), xlim = c(-75, -52)) +
  facet_grid(source ~ time, labeller = labeller(time = c("2018-11-22 00:00:00" = "00 UTC, 22 de Nov",
                                                         "2018-11-22 12:00:00" = "12 UTC, 22 de Nov",
                                                         "2018-11-23 00:00:00" = "00 UTC, 23 de Nov"),
                                                source = c("era5" = "ERA5",
                                                           "goes" = "GOES-16 Canal 13"))) +
  tag_facets() +
  labs(x = NULL, y = NULL, fill = "CAPE", color = "TB (ºC)") +
  theme_minimal(base_size = 9) +
  theme(tagger.panel.tag.background = element_rect(color = "white"))

```

## Observaciones 

Durante el periodo de estudio se realizaron diferentes experimentos para evaluar el impacto de diferentes fuentes de observaciones, entre los que se incluyen datos convecionales oficiales de superficie y altura, redes privadas de estaciones meteorológicas automáticas de superficie, vientos derivados de satelite, y radianzas en cielo claro. También se utilizaron observaciones para cuantificar la calidad de los análisis y pronósticos. 

### Conjuntos de observaciones asimiladas 

#### Convencionales 

Las observaciones convencionales (EMC) utilizadas forman parte del flujo de datos del Sistema Global de Asimilación de Datos (GDAS). Se asimilarán las observaciones convencionales incluidas en los archivos Binary Universal Form for Representation of Meteorological Data (PREPBUFR) generados por NCEP. Los archivos PREPBUFR incluyen observaciones de superficie procedentes de 117 estaciones meteorológicas de superficie (EMS), barcos, y observaciones de altura procedentes de 13 sitios de lanzamiento de radiosondeos y aviones dentro del área en estudio. Los triángulos naranjas de la Figura \@ref(fig:dominio)a indican la ubicación de las estaciones de superficie incluidas en este experimento. La frecuencia de estas observaciones varia entre 1 hora para las estaciones de superficie y 12/24 horas para las radiosondas. Las observaciones del viento en superficie sobre los océanos (ASCATW) proceden de los dispersómetros y también se incluyen en los archivos PREPBUFR.

La tabla \@ref(tab:tabla-obs) enumera todos los tipos de observación (presión en superficie, temperatura, humedad específica y viento) disponibles para cada fuente de observación, junto con el error asociado para cada una definidos de acuerdo a la configuración por defecto del sistema de asimilación usado en este trabajo. En algunos casos, el error varía con la altura y depende de la plataforma específica (avión y viento derivado del satélite). En cuanto al control de calidad aplicado a las observaciones convencionales, el sistema de asimilación realiza una primera comparación entre la innovación (la diferencia entre la observación y la observación simulada por el modelo para el campo preliminar) y un umbral predefinido que depende del error de observación (también incluido en la Tabla \@ref(tab:tabla-obs)).

#### Red de Estaciones Meteorológicas Automáticas {#ema}

También se asimilaron observaciones de 866 Estaciones Meteorológicas Automáticas (EMA) que forman parte de 17 redes de superficie públicas y privadas en la región. El conjunto de datos utilizado en este estudio fue obtenido del repositorio de datos de RELAMPAGO [@garcia2019]. Estas estaciones se indican como cuadrados verdes en la Figura \@ref(fig:dominio)a. Tienen mayor cobertura espacial que las EMC y una frecuencia de muestreo de 10 minutos en la mayoría de los casos. Todas las estaciones miden temperatura, pero sólo 395 estaciones proporcionan humedad, 422 la presión y 605 el viento. 
Los errores de observación utilizados para asimilar estas observaciones son los mismos que para las observaciones de EMC (véase la tabla \@ref(tab:tabla-obs)).


#### Vientos estimados por satélite 

Las observaciones de viento derivadas de los satélites también se incluyen en los archivos PREPBUFR disponibles cada 6 hs, y consisten en estimaciones de GOES-16 (utilizando los canales visible, infrarrojo y de vapor de agua) y METEOSAT 8 y 11 (utilizando los canales visible y de vapor de agua). Estos satélites son geoestacionarios y tienen una frecuencia de escaneo de 15 minutos, por lo que, ante la presencia de nubosidad para estimar el viento, generarán estimaciones que estarán diponibles en cada ciclo de asimilación. Las observaciones de viento derivadas de los satélites METEOSAT tienen una resolución de 3 km mientras que las de GOES-16 tienen una resolución de 10 km. Debido al dominio elegido y la cobertura de estos satélites, GOES-16 es la principal fuente de observaciones de vientos derivados de los satélites (99 % de las observaciones). Los errores de observación utilizados para asimilar estas observaciones siguen la configuración por defecto del GSI y se indican en la Tabla \@ref(tab:tabla-obs).


```{r tabla-obs}
fread(here("data/derived_data/tables/table1.csv")) %>% 
  kbl(caption = "Características de las observaciones asimiladas: El código de cada tipo de observación y su fuente, las variables disponibles, el error de observación y los umbrales de control de calidad utilizados.",
      col.names = c("Código", "Plataforma", "Variable", "Error", "Umbral de error"),
      booktabs = TRUE,
      escape = FALSE) %>% 
  kable_classic_2(full_width = FALSE) %>% 
  kable_styling(font_size = 9,
                position = "center") %>% 
  column_spec(1, width = "4.5em") %>% 
  column_spec(2, width = "5.5em") %>% 
  column_spec(3, width = "6em") %>% 
  column_spec(4:5, width = "8em") %>% 
  collapse_rows(columns = 1:2, valign = "middle", latex_hline = "major") %>% 
  footnote(symbol = c("El error de la observación varía con la altura.",
                      "Observationes por encima de 600 hPa son rechazadas.",
                      "El error de la observación depende del tipo de reporte."),
           symbol_manual = c("*", "**", "+"))
```

#### Radiancias de satélite

En este trabajo se utilizaron radiancias de satélites disponibles a través del flujo de datos del GDAS, que incluye observaciones en el espectro infrarrojos y microondas. Los sensores incluidos son el Advanced Microwave Sounding Unit - A (AMSU-A), Microwave Humidity Sounder (MHS), y 2 sensores multiespectrales; el Atmospheric Infrared Sounder (AIRS) y el Infrared Atmospheric Sounding Interferometer (IASI)  ubicados en distintas plataformas (ver Tabla \@ref(tab:table-rad)). Dado que el dominio regional que se utilizará en este trabajo se encuentra en latitudes medias y que los satélite de interés están en órbitas polares, cada sensor escanea la zona sólo dos veces al día con una cobertura espacial que depende de la franja de covertura satélite. Por esta razón, el número de observaciones de los satélites varía significativamente en cada ciclo de asimilación. En particular, los sensores multiespectrales proporcionaron entre 100 y 1000 observaciones por cada escaneo cada 12 horas, contribuyendo al 88 % de la cantidad total de radiancias de satélites polares asimiladas en los experimentos descriptos en la sección \@ref(config). 


```{r table-rad}
fread(here("data/derived_data/tables/tabla_radianzas.csv")) %>%
  .[, ":="(sensor = toupper(sensor),
           plataforma = toupper(plataforma),
           prop = paste0(prop, " ", "%"))] %>%
  .[order(.[,'sensor']), ] %>%
  .[] %>%
  kbl(booktabs = TRUE,
      escape = TRUE,
      col.names = linebreak(c("Sensor", "Plataforma", "Canales asimilados", "Porcentaje sobre el total")),
      caption = "Lista de los sensores disponibles cada plataforma, el número de canales aceptados para su asimilación y el porcentaje de observaciones asimiladas calculado sobre todas las observaciones de radiancias y todos los ciclos de asimilación correspondientes al experimento RAD.") %>%
  kable_styling(font_size = 9) %>%
  collapse_rows(1, valign = "top") %>%
  kable_classic_2(full_width = TRUE)
```


También se utilizaron observaciones del satélite geoestacionario GOES-16, en particular los 3 canales en el infrarrojo sensibles al vapor de agua del sensor *Advanced Baseline Imager* (ABI). Estas observaciones tienen una frecuencia temporal de 15 y una resolución espacial de 2 kilómetros. Al ser un satélite goestacionario, cada escaneo del sensor cubre la totalidad del dominio por lo que las observaciones estarán disponibles en cada ciclo de asimilación y el número de observaciones disponible solo dependerá de la cobertura de nubes en cada momento.


### Conjuntos de observaciones para verificación 

Para evaluar el desempeño del sistema de asimilación de datos presentado en esta tesis, utilizamos los siguientes conjuntos de observaciones: 

* **Datos horarios en niveles de presión de ERA5 [@era5pressure]:** Las variables de interés (temperatura del aire, humedad y viento) fueron interpoladas desde la reticula del reanalisis que tiene una resolución de 0.25$^{\circ}$ a la retícula del modelo para compararlas con el análisis de cada experimento. 

* **Multi-Network Composite Highest Resolution Radiosonde Data [@sondeos]:** radiosondeos en alta resolución lanzados desde varias ubicaciones durante el periodo de la campaña de campo RELAMPAGO en conjunto con las radiosondeos operativos del SMN. Sólo se utilizaron para la validación los sondeos que no ingresaron en el sistema de asimilación y que corresponden a los sitios de observación de la campaña. El periodo del experimento abarca las misiones *Intensive Observation Period* (IOP) 7 (21/11/2018) y 8 (22/11/2018), durante las cuales se lanzaron 74 radiosondos en una pequeña zona cercana al centro del dominio experimental (Figura \@ref(fig:dominio)b). Estas observaciones son de particular importancia ya que si bien corresponden a una región acotada del dominio, aportar información de alta resolución vertical y temporal ya que operacionalmente se lanzan sondeos una o dos veces al día.

* **IMERG Final Run [@huffman2018]:** estimación de la precipitación a partir de datos de la constelación de satelites GPM (por su nombre en inglés Global Precipitation  Measurement) con una resolución espacial de 0,01$^{\circ}$ y una resolución temporal de 30 minutos para validar la habilidad de los pronósticos de 1 hora para representar la precipitación sobre el dominio. La estimación de la precipitación se realiza combinando observaciones de sensores de microondas activos y pasivos que se complementa con estimaciones provenientes de sensores infrarojos a bordo de satélites polares. 

* **Datos del Sistema Nacional de Radares Meteorológicos (SINARAME):** Se utilizaron observaciones de radar para realizar una evaluación cualitativa y visual de la ubicacion e intensidad de la actividad convectiva. Los datos provienen de 9 radares ubicados en el dominio y son provistos por la red de radares Doppler de doble polarización en banda C [@deelia2017] con una frecuencia temporal de 10 minutos. Para este trabajo se utilizó únicamente la máxima reflectividad de la columna (COLMAX) más cercana al momento de análisis.

* **Observaciones de las redes de estaciones meteorógicas automáticas:** Las observaciones de EMA descriptas en la sección \@ref(ema) fueron utilizadas en la verificación de pronósticos inicializados a partir de los ánalisis generados. Estos pronósticos no incluyen asimilación de datos y por lo tanto estas observaciones son independientes y permiten evaluar calidad de los pronósticos en niveles bajos. s

## La asimilación de datos

La asimilación de datos combina de manera optima un pronóstico numérico o campo preliminar en un tiempo $t$ con las observaciones disponibles para ese mismo tiempo, generando un análisis [@carrassi2018]. Esta combinación optima toma en cuenta el error asociado al modelo meteorológico (errores de pronóstico) y el error de las observaciones (que resulta de los errores instrumentales y los errores de representatividad) y su error será menor a los errores originales. Por esta razón el análisis es considerado desde un punto de vista estadistico y bajo ciertas hipotesis, como la *mejor aproximación* disponible del estado real de la atmósfera.
 

(ref:ciclo-asimilacion-teorico) Esquema de un ciclo de asimilación típico. El tiempo de las observaciones y el campo preliminar deberá coincidir.

```{r ciclo-asimilacion-teorico, fig.align='center', out.width='100%',  fig.cap='(ref:ciclo-asimilacion-teorico)'}
knitr::include_graphics(here("figure/ciclo_asimilacion_teorico.png"))
```

Un ciclo de asimilación de datos típico se muestra en la Figura \@ref(fig:ciclo-asimilacion-teorico). En un tiempo dado se comparan las observaciones disponibles con el campo preliminar para ese mismo tiempo, generando así el análisis que se utilizará como condición inicial para un futuro pronóstico o campo preliminar. En el caso de modelos globales, típicamente cada ciclo de asimilación de 6 horas utiliza el campo preliminar previo, es decir el pronóstico a 6 horas inicializado a partir del análisis anterior y las observaciones disponibles para las 6 horas previas o en un periodo similar centrado en la hora del análisis. 

En este sentido tanto el modelo como las observaciones cumplen un rol fundamental en la asimilación. Por un lado las observaciones permiten incorporar información continua para corregir los pronósticos. Por el otro, el modelo permite *transportar* información de regiones donde existe mucha información disponible (por ejemplo, los continentes) a regiones donde las observaciones son escasas (zonas oceánicas) manteniendo los balances físicos que rigen los procesos atmosféricos. 


Existen distintas técnicas de asimilación de datos, cada una con sus ventajas y desventajas que fueron descriptas por @dillon2017 en su tesis doctoral. En este trabajo, al igual que en trabajos previos en Argentina, se utilizará la técnica *local ensemble transform Kalman filter* (LETKF, @hunt2007) que forma parte de un conjunto de técnicas basadas en Filtros de Kalman por ensambles [@evensen2009]. Los Filtros de Kalman utilizan el ensamble, un conjunto de pronósticos ligeramente diferentes que se resuelven simultaneamente para incluir los posibles estados de la atmósfera y provee información dependiente de la dinámica durante la ventana de asimilación y estimar el error del modelo a lo largo del tiempo. 

En el contexto de los Filtros de Kalman, el análisis o $x_a$ será el estado más probable de la atmósfera teniendo en cuenta las $m$ observaciones $y_o$ disponibles en un tiempo $t$. Para poder comparar y combinar el campo preliminar con las observaciones, este es interpolado a la ubicación de las observaciones. En determinados casos, por ejemplo cuando se trabaja con observaciones de satélite o radar, será necesario transformar las variables del modelo (ej. temperatura y humedad) para obtener las variables observadas (ej. temperatura de brillo). En la siguiente ecuación $H$ es el operador de las observaciones no lineal que se encarga de las interpolaciones y transformaciones necesarias sobre el campo preliminar $x_f$, representado como un vector de dimensión $n$. 

\begin{equation}
  x_a = x_f + K[y_o - H(x_b )]
  (\#eq:eq1)
\end{equation}

La diferencia entre las observaciones $y_o$ y el campo preliminar se denomina innovación. El análisis $x_a$ se obtiene aplicando las innovaciones al campo preliminar pesadas por una matriz $K$ o Ganancia de Kalman. Esta matriz de dimensión $n$ x $m$ que incluye información sobre los errores del pronóstico y de las observaciones como se observa en la ecuación \@ref(eq:eq3),

\begin{equation}
  K = BH^T (HBH^T + R^{-1})^{-1}
  (\#eq:eq3)
\end{equation}

donde $B$ es la matriz de covarianza de los errores del pronóstico y $R$ corresponde a la matriz de covarianza de los errores de las observaciones. La implementación de los los métodos de asimilación de datos suelen ser computacionalmente muy costosos, en parte debido a la estimación de la matriz $B$. 

\begin{equation}
  \mathrm{ B \approx \frac{1}{m-1} \sum_{k=1}^{m}(x_{f}^{k}-\overline{x}_f)(x_{f}^{k}-\overline{x}_f)^T}
  (\#eq:eq5)
\end{equation}

donde $k \; \epsilon \; [1,m]$ es el miembro *k-ésimo* del ensamble. Los métodos de Filtro de Kalman por Ensambles tienen la ventaja de estimar la matriz $B$ a partir de ensamble y actualizarla en cada ciclo de asimilación para incluir los errores dependientes de la dinámica del sistema.
Esta estimación será buena si el ensamble logra capturar los posibles estados futuros o en otras palabras si la dispersión es sufiente para acompañar los cambios en la incertidumbre de los pronosticos a lo largo de los ciclos de asimilación. El ensamble debe, a su vez, ser capaz de capturar la inestabilidad en el sistema cuyos errores tienen tasas de crecimiento muy rápidas. Si esto ocurre la estimación de $B$ será buena.

El método LETKF es una técnica eficiente ya que resuelve la ecuación \@ref(eq:eq1) en un espacio de dimensión reducida definido por los miembros del ensamble. Por lo tanto la matriz $K$ no se resuelve explicitamente eliminando la necesidad de computar inversa de matrices. Cómo en el resto de los métodos que usan filtro de Kalman, se localiza o restringe el área de influencia de las observaciones a un determinado radio de localización reduciendo el costo computacional necesario. La localización tiene además otra ventajas. Por un lado, y desde el punto de vista dinámico las inestabilidades en la atmósfera son de naturaleza local y por lo tanto el tamaño del ensamble necesario para representar estas inestabilidades será menor que si miramos el problema globalmente [@patil2001]. Por otro lado la localización evita la generación de covarianzas espureas entre observaciones que están alejadas entre si y son independientes reduciendo el ruido estádistico en la estimación del análisis. Además, este método calcula el análisis para cada punto de retícula individualmente, incorporando todas las observaciones que puedan tener influencia en ese punto al mismo tiempo permitiendo paralelizar los cálculos. De esta manera este método es hasta un orden de magnitud más rápido comparado con otros métodos desarrollados previamente [@whitaker2008].


### El sistema de asimilación GSI 

GSI por su nombre en inglés Gridpoint Statistical Interpolation, es un sistema de asimilación de datos de última generación, desarrollado inicialmente por el Environmental Modeling Center  (EMC) del NCEP. Se diseñó como un sistema 3DVAR tradicional aplicado en el espacio de puntos de retícula de los modelos para facilitar la implementación de covarianzas anisotrópicas no homogéneas [@wu2002; @purser2003; @purser2003a]. 
Está diseñado para funcionar en varias plataformas computacionales, crear análisis para diferentes modelos numéricos de pronóstico, y seguir siendo lo suficientemente flexible como para poder manejar futuros desarrollos científicos, como el uso de nuevos tipos de observación, una mejor selección de datos y nuevas variables de estado [@kleist2009].

Este sistema 3DVAR sustituyó al sistema de análisis operativo regional de punto de retícula del NCEP por el Sistema de Predicción de Mesoescala de América del Norte (NAM) en 2006 y al sistema de análisis global Spectral Statistical Interpolation (SSI) usado para generar las condiciones iniciales del Global Forecast System (GFS) en 2007 [@kleist2009]. 
En los últimos años, GSI ha evolucionado para incluir varias técnicas de asimilación de datos para múltiples aplicaciones operativas, incluyendo 2DVAR (por ejemplo, el sistema Real-Time Mesoscale Analysis (RTMA); @pondeca2011), la técnica híbrida EnVar (por ejemplo los sistemas de asimilación de datos para el GFS, el Rapid Refresh system (RAP), el NAM, el HWRF, etc.), y 4DVAR (por ejemplo, el sistema de asimilación de datos para el Sistema Goddard de Observación de la Tierra, versión 5 (GEOS-5) de la NASA; @zhu2008). 
GSI también incluye un enfoque híbrido 4D-EnVar que actualmente se utiliza para la generación del GFS. 

Además del desarrollo de técnias híbridas, GSI permite el uso métodos de asimilación por ensambles. Para lograr esto, utiliza el mismo operador de las observaciones que los métodos variacionales para comparar el campo preliminar con las observaciones. 
De esta manera los exaustivos controles de calidad desarrollados para los métodos variacionales también son aplicados en la asimilación por ensambles. 
El código EnKF fue desarrollado por el Earth System Research Lab (ESRL) de la National Oceanic and Atmospheric Administration (NOAA) en colaboración con la comunidad científica. 
Contiene dos algoritmos distintos para calcular el incremento del analisis, el serial Ensemble Square Root Filter (EnSRF, @whitaker2002) y el Local Ensemble Kalman Filter (LETKF, @hunt2007) aportado por Yoichiro Ota de la Agencia Meteorológica Japonesa (JMA). 

Para reducir el impacto de covarianzas espurias en el incremento que se aplica al análisis, los sistemas por ensamble aplican una localización a la matriz de covarianza de los errores de las observaciones $R$ tanto en la dirección horizontal como vertical. 
GSI usa un polinomio de orden 5 para reducir el impacto de cada observación de manera gradual hasta llegar a una distancia límite a partir de la cual el impacto es cero. La escala de localización vertical se define en términos del logarítmo de la presión y la escala horizontal usualmente se define en kilómetros. 
Estos parámetros son importantes a la hora de obtener un buen análisis y dependen de factores como el tamaño del ensamble y la resolución del modelo. La configuración utilizada para los experimentos de esta tesis se describe en la sección \@ref(configmodelo).

A su vez utiliza el Community Radiative Transfer Model (CRTM, @han2006) como operador de las observaciones de radiancias que calcula la temperatura de brillo simulada por el modelo para poder compararlo con las observaciones de sensores satelitales. 
GSI, además implementa un algoritmo de corrección de bias de las observaciones de radiancias de satélites.
La estimación hecha por el campo preliminar obtenida con el CRMT se compara con las observaciones de radiancia para obtener la innovación. 
Esta innovación a su vez se utiliza para actualizar los coeficientes que permiten estimar el bias de las observaciones que se utilizá para obtener una innovación actualizada. Este proceso puede repetirse varias veces hasta que la innovación y los coeficientes de corrección de bias converjan. 
Este algoritmo se describe en mayor detalle en la Sección \@ref(sat).

#### El modelo de transferencia radiativa CRTM 

El Community Radiative Transfer Model (CRTM, @liu2008) es un modelo de transferencia radiativa rápido que fue desarrollado conjuntamente por el NOAA Center for Satellite Applications and Research y el Joint Center for Satellite Data Assimilation (JCSDA). Es un modelo utilizado ampliamente por la comunidad de sensoramiento remoto ya que esdees de código abierto y se encuentra disponible para su uso públicamente. Se utiliza para la calibracion de instrumentos satelitales [@weng2013; @iacovazzi2020; @crews2021], y a su vez para generar retrievals a partir de observaciones satelites [@boukabara2011; @hu2019; @hu2021]. De especial importancia para este trabajo, es utilizado como operador de observaciones en la asimilacion de radianzas satelitales [@tong2020; barton2021]. 

El CRTM es capaz de simular radiancias de microondas, infrarrojas y visibles utilizando perfiles atmosféricos de presión, temperatura, humedad y otras especies como el ozono. Recientemente @cutraro2021 evaluaron su despeño en la region con buenos resultados en la simulación de observaciones de GOES-16. 

El CRTM es un modelo de transferencia radiativa *"sensor-based"*, es decir que contiene parameterizaciones y tablas de coefficientes precalculadas especificamente para los sensores operativos. El CRTM se utiliza ampliamente para la asimilación de datos satelitales tanto microondas e infrarrojos. Incluye módulos que calculan la radiación térmica medida por satélite a partir de la absorción gaseosa, la absorción y dispersión de la radiación por aerosoles y nubes, y la emisión y reflexión de la radiación por la superficie terrestre. La entrada al CRTM incluye variables de estado atmosférico -por ejemplo, temperatura, vapor de agua, presión y concentración de ozono en capas definidas por el usuario, y variables y parámetros de estado de la superficie, incluyendo la emisividad, la temperatura de la superficie y el viento.

El modelo forward del CRTM permite simular observaciones satelitales de radiancias a partir del estado de la atmósfera. Esto es necesario para la asimilación de radiancias pero también es utilizado para verificar la precisión y los errores de estas observaciones.  

El cálculo de las observaciones simuladas tiene un costo computacional muy alto ya que requiere transporner un matriz de grandes dimensiones y la minimización de una función de costo. Esta matriz K se construye a partir de las derivadas parciales de las radiancias con respecto a parámetros geofísicos. CRTM permite hacer estos cálculos de manera rápida para que pueda usarse en contextos operacionales. 

Para obtener resultados rápidos, CRTM aplica ciertas simplificaciones y aproximaciones a la hora de resolver la ecuación de transferencia radiativa. En primer lugar asume que la atmósfera terrestre está formada por capas plano-paralelas y homogeneas en equilibrio termodinámico y donde los efectos tridimensionales y de polarización pueden ser ignorados.

En contextos de cielos despejados, además se asume que no existe dispersión y solo se considera la absorción de los gases en la atmósfera. En cielos nubosos y canales en el infrarrojo también se asume que no existe dispersión. Sin embargo, en el caso de canales de microondas la dispersión generada por las nubes es incluida. En este caso la ecuación de transferencia radiativa no se puede resolver anaíticamente y se recurre a modelos numéricos. 


#### Asimilación de radiancias en GSI {#sat}

El preprocesamiento y control de calidad de los datos es un paso esencial en la asimilación de radiancias y depende de cada sensor y canal. Esto incluye principalemnte un *thinning* especial, la correcion del bias, y en particular en este estudio la deteccion de observaciones de cielos nubosos. Primero se aplicó un thinning espacial. Durante el proceso de thinning las observaciones que se van a asimilar se eligen en función de su distancia a los puntos de la retícula del modelo, la calidad de la observación (basada en la información disponible sobre la calidad de los datos) y el número de canales disponibles (para el mismo píxel y sensor) que han pasado el control de calidad. Además, el algoritmo de thnning prefiere las observaciones sobre el mar a las de la tierra o nieve [@hu2018]. El objetivo al aplicar thinning es evitar incorporar información de procesos de escalas menores a las que puede representar el modelo. 


Luego del thinning, se aplica la corrección de bias. La metodología de corrección de bias implementada en GSI tiene una componente dependiente de características termodinámicas del aire y otro dependiente del ángulo de escaneo [@zhu2014] y se calcula como una polinomio lineal de N predictores $p_i(x)$, con coeficientes asociados $\beta_i$. Por lo tanto, la temperatura de brillo corregida por bias ($BT_{cb}$) puede obtenerse como

\begin{equation}
  \mathrm{\mathit{BT_{cb}} =\mathit{ BT} + \sum_{i = 0}^{N} \beta_i p_i (x)}
  (\#eq:eq12)
\end{equation}

GSI tiene un término de corrección de bias constante ($p_0 = 1$) mientras que los términos restantes y sus predictores son el contenido de agua líquida de las nubes (CLW), la tasa de cambio de temperatura con la presión, el cuadrado de la tasa de y la sensibilidad de la emisividad de la superficie. El bias dependiente del ángulo de escaneo se modela como un polinomio de 4$^\circ$ orden [@zhu2014]. 

En el sistema GSI, los coeficientes $\beta_i$ se entrenan utilizando un método de estimación variacional que genera los $\beta_i$ que proporciona el mejor ajuste entre la simulación y las observaciones. 


La metodología detección de pixeles nubosos depende de la longitud de onda de las observaciones. Para las radiancias de microondas, las observaciones potencialmente contaminadas por nubes se detectan utilizando los índices de dispersión y del  Liquid Water Path (LWP) calculados a partir de diferencias entre distintos canales de cada sensor [@weston2019; @zhu2016]. Para los canales infrarrojos, las observaciones contaminadas por nubes se detectan utilizando el perfil de transmitancia calculado por el modelo CRTM. Además, GSI comprueba la diferencia entre las observaciones y la temperatura de brillo simulada para detectar los píxeles nublados. Un caso particular son las las observaciones de ABI ya que se utiliza la mascara de nubes que se genera como producto de nivel 2 y que está disponible con la misma resolución que las observaciones. Esta máscara de nubes se genera combinando información de 8 canales del sensor ABI desde el punto de vista espacial y temporal.

Por otro lado, el control de calidad de GSI filtra aquellas observaciones de canales cercanos al rango visible sobre superficies de agua con un ángulo cenital mayor a 60$^{\circ}$ para rechazar aquellas observaciones que pudieran estar contaminadas por reflexión. Para las observaciones en el infrarrojos y microondas también realiza una chequeo de la emisividad para detectar observaciones contaminadas por efecto de la superficie.   

Finalmente se aplica un *gross check*, es decir, se compara la diferencia entre la observación y la observación simulada por el modelo y un umbral predefinido que depende del error de observación para rechazar observaciones erroneas. La ubicación vertical de cada observación de radiancia se estimó como el nivel del modelo en el que se maximizaba su función de peso calculada por el CRTM. La función de peso de cada canal corresponde al cambio en la transmitancia con la altura y su máximo describe la capa de la atmósfera desde donde la radiación captada por el canal fue emitida. Los sensores multiespectrales tienen una buena cobertura vertical y son capaces de captar desde la baja troposfera hasta la baja estratosfera. Los canales elegidos para la asimilación y sus errores asociados se definieron teniendo en cuenta la configuración que GSI para generar los análisis y pronósticos de GFS, el tope del modelo elegido en este trabajo (50 hPa) y la posible influencia de la superficie.



## Configuración del sistema de asimilación {#configmodelo}

Las simulaciones numéricas que conforman los experimentos que se discuten en este trabajo se realizan utilizando la versión 3.9.1 de modelo WRF [@skamarock2008]. 
Se utilizó una resolución horizontal de 10 km y 37 niveles en la vertical con el tope del modelo en 50 hPa. 
Las condiciones iniciales y de contorno surgen del análisis del Global Forecast System (GFS, resolución horizontal de 0,25$^{\circ}$ y resolución temporal de 6 horas; @cisl_rda_ds084.1). 
El dominio de 150 x 200 puntos de retícula cubre la zona indicada en la Figura \@ref(fig:dominio) para capturar el desarrollo del SCM durante el periodo simulado. 

Los análisis se generaron utilizando la implementación LETKF (V1.3, @hunt2007) que forma parte del sistema de análisis Gridpoint Statistical Interpolation (GSI V3.8; @shao2016). 
Se utilizó un enfoque de actualización rápida con análisis horario y una ventana de asimilación centrada, lo que significa que se asimilaron todas las observaciones dentro de $\pm$ 30 minutos del tiempo de análisis. 
Además, las observaciones se asimilaron usando un enfoque 4D, es decir, comparándolas con el first guess más cercano disponible con una frecuencia de 10 minutos. 
Para las observaciones de satelite, se utilizó el Community Radiative Transfer Model versión 2.3 (CRTM; @han2006) como operador de observaciones para calcular las temperaturas de brillo simuladas por el modelo. 

Utilizamos un conjunto de 60 miembros, cuya media al principio del ciclo de AD se inicializa utilizando el análisis deterministico del GFS al que se le suman perturbaciones aleatorias para generar el ensamble incial. Las perturbaciones se generaron como diferencias escaladas entre dos estados atmosféricos aleatorios obtenidos a partir de los datos del Reanálisis del Sistema de Predicción del Clima (CFSR) con una resolución horizontal de 0,5$^{\circ}$ que tiene una evolución temporal suave [@necker2020; @maldonado2021]. De este modo, preservamos el equilibrio casi hidrostático y geostrófico de las escalas mayores. Este método ayuda a evitar una subestimación del spread del ensamble [@ouaraini2015]. Las perturbaciones  también se aplicaron en los bordes laterales para mantener niveles adecuados de spread dentro del dominio del ensamble. 

Además de las perturbaciones aleatorias en los bordes laterales, se utilizó un esquema de multifísicas para representar mejor la incertidumbre en el modelo dentro del sistema de AD. Utilizamos 9 configuraciones diferentes que consisten en la combinación de 3 esquemas de convección húmeda (Kain-Fritsch, @kain2004; Grell-Freitas, @grell2013; y Betts-Miller-Janjic, @janjic1994) y 3 esquemas de capa límite planetaria (Esquema de la Universidad de Yonsei, @hong2006; Esquema Mellor-Yamada-Janjic, @janjic1994; y Mellor-Yamada Nakanishi Niino, @nakanishi2009). La distribución de estas parametrizaciones entre los 60 miembros del ensamble se muestra en la Tabla \@ref(tab:miembros-desc). Todos los miembros del conjunto utilizan las mismas parametrizaciones del modelo de superficie terrestre (Noah-MP, @chen2001), de microfísica (esquema de un solo momento de 6 clases del WRF, @hong2006a) y de procesos radiativos (esquema de onda corta y onda larga del RRTMG [@iacono2008]).

```{r miembros-desc}
data.table(mem = as.character(formatC(1:60, flag = "0", width = 3)),
                     fisica = rep(c("KF-YSU", 
                                    "BMJ-YSU",
                                    "GF-YSU",
                                    "KF-MYJ",
                                    "BMJ-MYJ",
                                    "GF-MYJ",
                                    "KF-MYNN2",
                                    "BMJ-MYNN2",
                                    "GF-MYNN2"), length.out = 60)) %>% 
  setDT() %>% 
  .[, c("Cumulus", "PBL") := tstrsplit(fisica, split = "-")] %>% 
  .[, .(mem = paste(as.numeric(mem), collapse = ", ")), by = .(PBL, Cumulus)] %>% 
  dcast(Cumulus ~ PBL, value.var  = "mem") %>% 
  kable(booktabs = TRUE, caption = "Generación de los 60 miembros del ensamble multifísica como combinación de parametrizaciones de Cumulus y PBL", 
        align = "cccc") %>% 
  add_header_above(c(" " = 1, PBL = 3)) %>% 
  kable_classic_2(full_width = FALSE) %>% 
  kable_styling(font_size = 9,
                position = "center") %>% 
  # column_spec(1, width = "1em") %>% 
  column_spec(2:4, width = "8em")
```


Para reducir el efecto de las correlaciones espurias en la estimación de las covarianzas de los errores de las observaciones, utilizamos un radio de localización horizontal de 180 km y un radio de localización vertical de 0,4 (en coordenadas del logaritmo de la presion ) como en @dillon2021 para todos los tipos de observaciones. 
Se aplicó con un parámetro de inflación $\alpha=0,9$ para mitigar el impacto de los errores de muestreo y para considerar los errores del modelo que no se tienen en cuenta en el enfoque mutifísica del ensamble [@whitaker2012].

(ref:dominio) a) Dominio utilizado para las simulaciones (recuadro negro), dominio interior utilizado para la comparación entre experimentos (recuadro rojo), la región mostrada en b) (recuadro azul claro), y la ubicación de las Estaciones Meteorológicas Automáticas (EMA, cuadrados verdes) y las Estaciones Meteorológicas Convencionales (EMC, triángulos naranjas). b) Ubicación de los lanzamientos de radiosondeos durante RELAMPAGO. Los puntos verdes corresponden a los radiosondeos lanzados durante el IOP 7, los triángulos naranjas son radiosondeos lanzados durante el IOP 8, y los cuadrados morados son radiosondeos lanzados fuera de los periodos de medición intensiva. También se muestra la topografía en metros (sombreada).

```{r dominio, fig.cap="(ref:dominio)", out.width="80%", fig.align='center'}

oficiales <- fread(here("data/derived_data/sample_obs/E2_asim_conv_20181121120000.ensmean"), 
                   na.strings = c("0.100E+11", "-0.100E+06", "-99999.90", "-100000.00")) %>% 
  .[, c("V2", "V4") := NULL] %>% 
  setnames(colnames(.), c("var", "stationID", "type", "dhr", "lat", "lon", "pressure", "usage.flag", "flag", "obs", "obs.guess", "obs2", "obs.guess2", "rerr")) %>% 
  .[type %in% c(181, 281)] %>% unique(by = c("stationID")) %>%
  .[!str_detect(stationID, pattern = "[A-Z]")] %>% 
  .[, source := "Sfc - Official"]

no_oficiales <- fread(here("data/derived_data/sample_obs/E5_asim_conv_20181121120000.ensmean"), 
                      na.strings = c("0.100E+11", "-0.100E+06", "-99999.90", "-100000.00")) %>% 
  .[, c("V2", "V4") := NULL] %>% 
  setnames(colnames(.), c("var", "stationID", "type", "dhr", "lat", "lon", "pressure", "usage.flag", "flag", "obs", "obs.guess", "obs2", "obs.guess2", "rerr")) %>% 
  .[type %in% c(181, 187)] %>% 
  .[!str_detect(stationID, "SMN")] %>%
  .[!str_detect(stationID, "^SC")] %>%
  .[!(stationID %in% oficiales$stationID)] %>% 
  unique(by = c("stationID")) %>% 
  .[, source := "Sfc - Non-official"]

obs <- rbind(no_oficiales, oficiales)

lista_sondeos <- fread(here("data/derived_data/sample_obs/lista_sondeos.csv")) %>% 
  .[, periodo := fcase(nominal_launch_time %between% c(ymd_hms("20181121150000"), ymd_hms("20181121210000")),  "IOP 7", 
                       nominal_launch_time %between% c(ymd_hms("20181122140000"), ymd_hms("20181122200000")),  "IOP 8", 
                       default = "Otros")
  ]

dominio <- fread(here("data/derived_data/sample_obs/dominio_hgt.csv")) %>% 
  .[, c("x", "y") := wrf_project(lon, lat)]

g1 <- dominio %>% 
  ggplot(aes(x, y)) +
  geom_contour_fill(aes(z = hgt), proj = norargentina_lambert,
                    breaks = seq(0, 6000, 500)) +
  scale_fill_gradient(low = "#f2f2f2", high = "#333333",
                      name = NULL,
                      breaks = seq(0, 6000, 1000),
                      guide = NULL) +
  geom_mapa() +
  geom_point(data = obs, aes(ConvertLongitude(lon), lat, 
                             color = source, shape = source), 
             size = 1, alpha = 0.8) + 
  geom_rect(aes(xmin = -66.5, xmax = -61.5, ymin = -35.5, ymax = -29), 
            color = "#40BDEC", alpha = 0) +
  scale_shape_manual(name = NULL,  
                     breaks = c("Sfc - Non-official", "Sfc - Official"),
                     labels = c("EMA","EMC"), values = c(15, 17),
                     guide = guide_legend(override.aes = list(size = 2))) +
  scale_color_manual(name =  NULL, 
                     values = c("Sfc - Non-official" = "#00695c", 
                                "Sfc - Official" = "#FD8002"),
                     breaks = c("Sfc - Non-official", "Sfc - Official"),
                     labels = c("EMA","EMC"),
                     guide = guide_legend(override.aes = list(size = 2))) +
  geom_point(data = square, aes(lon, lat), size = 0.2) +
  geom_point(data = square2, aes(lon, lat), size = 0.2, color = "#CC3311") +
  theme_minimal(base_size = 10) +
  theme(legend.box = "horizontal",
        legend.position = c(0.1, 0.95),
        legend.background = element_rect(fill = "white", color = "white")) 


temp <- dominio %>% 
  ggplot(aes(x, y)) +
  geom_contour_fill(aes(z = hgt), proj = norargentina_lambert,
                    breaks = seq(0, 6000, 500)) +
  scale_fill_gradient(low = "#f2f2f2", high = "#333333",
                      name = "Altura (m)",
                      breaks = seq(0, 6000, 1000),
                      guide = guide_colorstrip(barwidth = 20,
                                               barheight = 0.5)) +
  geom_mapa() +
  coord_sf(ylim = c(-35.5, -29), xlim = c(-66.5, -61.5)) +
  theme_minimal(base_size = 11) +
  theme(legend.position = "bottom") 

legend <- get_legend(temp)

g2 <- dominio %>% 
  ggplot(aes(x, y)) +
  geom_contour_fill(aes(z = hgt), proj = norargentina_lambert,
                    breaks = seq(0, 6000, 500)) +
  scale_fill_gradient(low = "#f2f2f2", high = "#333333",
                      name = NULL,
                      breaks = seq(0, 6000, 1000),
                      guide = NULL) +
  geom_mapa() +
  coord_sf(ylim = c(-35.5, -29), xlim = c(-66.5, -61.5)) +
  geom_jitter(data = lista_sondeos, aes(lon, lat, 
                                        color = periodo,
                                        shape = periodo), 
              alpha = 0.5, size = 1.5, width = 0.03, height = 0.03) +
  scale_color_brewer(palette = "Dark2",
                     guide = guide_legend(override.aes = list(size = 2,
                                                              alpha = 1))) +
  labs(color = NULL, shape = NULL) +
  theme_minimal(base_size = 11) +
  theme(legend.box = "horizontal",
        legend.position = c(0.16, 0.92),
        legend.background = element_rect(fill = "white", color = "white")) 

ggdraw(plot_grid(plot_grid(g1, g2, ncol = 2, rel_widths = c(1, 0.5), 
                           labels = c("a)", "b)"), label_size = 11), legend, 
                 ncol = 1, rel_heights = c(1, 0.08)))
```

Los errores de las observaciones utilizados fueron definidos de acuerdo a las tablas de errores disponibles como parte del sistema GSI. Para las observaciones de radiancias polares se aplicó un thinning con una retícula de 60 km siguiendo  @singh2016, @jones2013 y @lin2017a ya utilizan configuraciones de modelo similares a la usada en este trabajo. Para las observaciones de GOES-16 se realizaron pruebas de sensibilidad para determinar la resolución de thinning más apropiada para este tipo de observaciones que se describen en la sección  \@ref(thinning). 

Los coeficientes de corrección de bias para las observaciones de satélites polares se inicializaron a las 18 UTC del 18 de noviembre de 2018 a partir los coeficientes generados para la misma hora por el sistema GFS. El sistema de asimilación se configuró para utilizar una varianza de error de los coeficientes constante de 0,01 para evitar grandes ajustes en los coeficientes estimados en cada momento. Por razones que se describen en la seccion \@ref(asim-goes) se decidió no aplicar corrección de bias a las observaciones de GOES-16.

## Métodos de verificación 

Se seleccionaron un conjunto de métricas para evaluar diferentes aspectos del análisis obtenido para cada experimento y los pronósticos inicializados a partir de ellos. Estas métricas incluyen una validación de cómo se cuantifica la incertidumbre en el first guess y en el análisis, y cómo los diferentes experimentos se ajustan a un conjunto independiente de observaciones que no se asimilan. 

Para evaluar la consistencia de la estimación de la incertidumbre en el first guess y en el análisis utilizamos la Reduced Centered Random Variable o RCRV (@candille2007) que se define como:

\begin{equation}
  \mathrm{RCRV} = \frac{m - x_o}{\sqrt{\sigma_o^2 + \sigma^2}}
  (\#eq:eq6)
\end{equation}

donde $x_o$ es la observación asimilada y su error $\sigma_o$, $m$ la media ensamble del análisis en el espacio de las observaciones, y la desviación estándar $\sigma$ del ensamble 
La media de $RCRV$ calculada sobre todas las realizaciones representa el sesgo de la media del conjunto con respecto a las observaciones normalizadas por la incertidumbre estimada:

\begin{equation}
  \mathrm{\mathit{mean RCRV} = E[RCRV]}
  (\#eq:eq7)
\end{equation}

La desviación estándar de la $RCRV$ o $sd RCRV$ mide la concordancia de la dispersión del ensamble y el error de observación con respecto a la distancia entre la media del ensamble y las observaciones, y por lo tanto, la sobre o subdispersión sistemática del ensamble:

\begin{equation}
  \mathit{sd RCRV} = \sqrt{\frac{1}{M -1}\sum_{i=1}^{M}(RCRV_i - \mathit{mean RCRV})^2}
  (\#eq:eq8)
\end{equation}

donde $M$ es el tamaño del ensamble. Suponiendo que el error de observación fue estimado con precisión, un $sd RCRV > 1$ indica que el ensamble es subdispersivo (es decir, la distancia entre las observaciones y los pronósticos es mayor de lo esperado), y un $sd RCRV < 1$ indica que el conjunto es sobredispersivo (es decir, la distancia entre las observaciones y los pronósticos es menor de lo esperado). Un sistema consistente no tendrá sesgo ($media RCRV = 0$) y una desviación estándar igual a 1 ($sd RCRV = 1$). 

Para analizar el ajuste del first guess y el análisis a un conjunto de observaciones independientes se calculó la raiz del error cuadrático medio (RMSE) y el BIAS:

\begin{equation}
  \mathit{RMSE} = \sqrt{\frac{1}{N}\sum_{i = 1}^{N} (X_i - O_i)^{2}}
  (\#eq:eq9)
\end{equation}  


\begin{equation}
  \mathit{BIAS} = \frac{1}{N}\sum_{i = 1}^{N} (X_i - O_i)
  (\#eq:eq10)
\end{equation}

donde $X$ representa el modelo interpolado al espacio de la observaciones, $O$ las observaciones independientes, y N es el tamaño de la muestra. 

Para comparar la precipitación pronosticada por el first-guess con las estimaciones de precipitación de IMERG, calculamos el Fractions Skill Score (FSS, @roberts2008) para diferentes radios de influencia y umbrales de precipitación: 

\begin{equation}
  \mathrm{\mathit{FSS} = 1-\frac{\sum_{i=1}^{N} ({P_x}_i-{P_o}_i)^{2}}{\sum_{i=1}^{N} ({P_x}_i)^{2}+\sum_{i=1}^{N} ({P_o}_i)^{2}}}
    (\#eq:eq11)
\end{equation}
  
  
donde $P_{oi}$ es la proporción de puntos de reticula en el subdominio $i-th$, definido por el radio de influencia, donde la que la precipitación acumulada observada es mayor que un umbral especificado. Siguiendo a @roberts2020, $P_{xi}$ se calcula sobre el ensamble completo y cuantifica de la probabilidad de que la precipitación sea mayor al mismo umbral en cada punto de cuadrícula, y luego promediando sobre el subdominio $i-th$. 

Para los pronósticos por ensambles se calculó la probabilidad de precipitación por encima de determinados umbrales en cada punto de retícula como la proporción de miembros del ensamble que pronósticaron precipitación por encima de cada umbral. Además se generaron gráficos de confiabilidad [@wilks2011] con intervalos de probabilidades pronósticadas de 10% para analizar la calibración de los pronósticos inicializados a partir de los análisis de cada experimento.  



## Recursos computacionales 

Todos los experimentos corrieron en la supercomputadora Cheyenne del Centro Nacional de Investigación Atmosférica (NCAR) [@Cheyenne2019]. El posprocesamineto y análisis se realizó en [CIMA]. El análisis de datos se generó utilizando el lenguaje de programación R [@rcoreteam2020], utilizando los paquetes data.table [@dowle2020] y metR [@campitelli2020], entre otros.
Todos los gráficos se han realizado con ggplot2 [@wickham2009] y la versión final de la tesis se generó con knitr, rmarkdown [@xie2015; @allaire2019] y tesisdown [esperando respuesta del desarrollador].


